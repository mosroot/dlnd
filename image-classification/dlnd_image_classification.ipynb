{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import warnings \n",
    "\n",
    "if not tf.test.gpu_device_name(): \n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.') \n",
    "else: print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 3:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]\n",
      "\n",
      "Example of Image 999:\n",
      "Image - Min Value: 1 Max Value: 238\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 8 Name: ship\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQGGCHgAKE/QAUNj/Aso3KQItF6vRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23d166f1b70>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 999\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    a = 0\n",
    "    b = 255\n",
    "    return (x-a)/(b-a)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    y = np.zeros((len(x),10))\n",
    "    for i in range(len(x)):\n",
    "        y[i,x[i]] = 1\n",
    "    return y\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_hot_encode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2e43b03e04f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[1;31m# Preprocess Training, Validation, and Testing Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_and_save_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcifar10_dataset_folder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot_encode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'one_hot_encode' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None] + list(image_shape), \"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, None, \"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    shape = list(conv_ksize + (dimension[-1], )+(conv_num_outputs, ))\n",
    "    \n",
    "    filter_weights = tf.Variable(tf.truncated_normal(shape, 0, 0.1))\n",
    "    filter_bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    padding = 'SAME'\n",
    "    \n",
    "    conv_layer = tf.nn.conv2d(x_tensor, filter_weights, list((1, )+conv_strides+(1, )), padding)\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, filter_bias)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    conv_layer = tf.nn.max_pool(conv_layer, ksize = [1]+list(pool_ksize)+[1], strides=[1]+list(pool_ksize)+[1], padding='SAME')\n",
    "    \n",
    "    \n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from numpy import prod\n",
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    return tf.reshape(x_tensor, [-1, prod(dimension [1: ] )])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全连接的层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    shape = list ((dimension[-1], )+(num_outputs, ) )\n",
    "\n",
    "    weight = tf.Variable(tf.truncated_normal (shape, 0, 0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "\n",
    "    return tf.nn.relu(tf.add(tf.matmul(x_tensor,weight), bias))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    shape = list((dimension[-1], ) + (num_outputs, ))\n",
    "\n",
    "    weight = tf.Variable(tf.truncated_normal (shape, 0, 0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    return tf.add(tf.matmul(x_tensor,weight), bias)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    cnn = conv2d_maxpool(\n",
    "    x, conv_num_outputs = 18,\n",
    "        conv_ksize = (6,6), conv_strides = (1,1),\n",
    "        pool_ksize = (2,2), pool_strides = (1,1)\n",
    "    )\n",
    "\n",
    "    cnn = tf.nn.dropout (cnn, keep_prob)\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    cnn = flatten(cnn)\n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    cnn  = fully_conn(cnn, 333)\n",
    "    \n",
    "    cnn = tf.nn.dropout(cnn, keep_prob)\n",
    "\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    cnn = output(cnn, 10)\n",
    "    # TODO: return output\n",
    "    return cnn\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run (\n",
    "    optimizer, feed_dict = {\n",
    "        x:feature_batch,\n",
    "        y:label_batch,\n",
    "        keep_prob:keep_probability\n",
    "        \n",
    "    }\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict = {\n",
    "                          x:feature_batch,\n",
    "                          y:label_batch,\n",
    "                          keep_prob:1.0                        \n",
    "                      })\n",
    "    valid_acc = sess.run(accuracy, feed_dict = {\n",
    "        x:valid_features,\n",
    "        y:valid_labels,\n",
    "        keep_prob:1        \n",
    "    })\n",
    "    print('Loss: {:.4f} Validation Accuracy: {:.4f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "keep_probability = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.3037 Validation Accuracy: 0.1320\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.2977 Validation Accuracy: 0.1506\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.2968 Validation Accuracy: 0.1736\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 2.2939 Validation Accuracy: 0.1830\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 2.2901 Validation Accuracy: 0.1880\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 2.2836 Validation Accuracy: 0.1960\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 2.2695 Validation Accuracy: 0.2102\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 2.2591 Validation Accuracy: 0.2186\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 2.2349 Validation Accuracy: 0.2310\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 2.2067 Validation Accuracy: 0.2362\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 2.1696 Validation Accuracy: 0.2616\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 2.1345 Validation Accuracy: 0.2724\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 2.0262 Validation Accuracy: 0.3116\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 2.0158 Validation Accuracy: 0.3136\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.9719 Validation Accuracy: 0.3208\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.9345 Validation Accuracy: 0.3240\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.8836 Validation Accuracy: 0.3472\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.8995 Validation Accuracy: 0.3506\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.8512 Validation Accuracy: 0.3528\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.8562 Validation Accuracy: 0.3674\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.8279 Validation Accuracy: 0.3696\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.8060 Validation Accuracy: 0.3708\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.7893 Validation Accuracy: 0.3776\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.7842 Validation Accuracy: 0.3772\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.7800 Validation Accuracy: 0.3862\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.7618 Validation Accuracy: 0.3862\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.7418 Validation Accuracy: 0.3912\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.7527 Validation Accuracy: 0.3856\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.7365 Validation Accuracy: 0.3846\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.7100 Validation Accuracy: 0.4048\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.7195 Validation Accuracy: 0.3886\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.7082 Validation Accuracy: 0.3962\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.6933 Validation Accuracy: 0.4148\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.6769 Validation Accuracy: 0.4104\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.6811 Validation Accuracy: 0.4200\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.6592 Validation Accuracy: 0.4220\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.6586 Validation Accuracy: 0.4160\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.6488 Validation Accuracy: 0.4248\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.6256 Validation Accuracy: 0.4304\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.6216 Validation Accuracy: 0.4382\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.6086 Validation Accuracy: 0.4374\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 1.5897 Validation Accuracy: 0.4470\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 1.5912 Validation Accuracy: 0.4398\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 1.5822 Validation Accuracy: 0.4446\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 1.5712 Validation Accuracy: 0.4508\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 1.5467 Validation Accuracy: 0.4564\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 1.5477 Validation Accuracy: 0.4524\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 1.5412 Validation Accuracy: 0.4486\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 1.5380 Validation Accuracy: 0.4572\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 1.5277 Validation Accuracy: 0.4620\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "print('Checking the Training on a Single Batch...')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.2982 Validation Accuracy: 0.1052\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 2.2996 Validation Accuracy: 0.1362\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 2.2990 Validation Accuracy: 0.1378\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 2.2967 Validation Accuracy: 0.1568\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 2.2971 Validation Accuracy: 0.1542\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.2940 Validation Accuracy: 0.1826\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 2.2945 Validation Accuracy: 0.1934\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 2.2824 Validation Accuracy: 0.2226\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 2.2744 Validation Accuracy: 0.2220\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 2.2694 Validation Accuracy: 0.2206\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.2502 Validation Accuracy: 0.2202\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 2.2218 Validation Accuracy: 0.2368\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 2.1702 Validation Accuracy: 0.2532\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 2.1625 Validation Accuracy: 0.2516\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 2.1172 Validation Accuracy: 0.2598\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 2.1321 Validation Accuracy: 0.2582\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 2.0862 Validation Accuracy: 0.2662\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 2.0741 Validation Accuracy: 0.2822\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 2.0300 Validation Accuracy: 0.2788\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 2.0411 Validation Accuracy: 0.2730\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 2.0738 Validation Accuracy: 0.2778\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 2.0093 Validation Accuracy: 0.2950\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 1.9565 Validation Accuracy: 0.3208\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 1.9680 Validation Accuracy: 0.2996\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 1.9364 Validation Accuracy: 0.3200\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.9905 Validation Accuracy: 0.3262\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 1.9382 Validation Accuracy: 0.3368\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 1.8727 Validation Accuracy: 0.3566\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 1.9113 Validation Accuracy: 0.3108\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 1.8512 Validation Accuracy: 0.3600\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.9305 Validation Accuracy: 0.3446\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 1.8273 Validation Accuracy: 0.3688\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 1.7820 Validation Accuracy: 0.3784\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 1.7870 Validation Accuracy: 0.3640\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 1.7984 Validation Accuracy: 0.3662\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.8527 Validation Accuracy: 0.3748\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 1.8149 Validation Accuracy: 0.3600\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 1.7075 Validation Accuracy: 0.3928\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 1.7349 Validation Accuracy: 0.3770\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 1.7573 Validation Accuracy: 0.3708\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.8303 Validation Accuracy: 0.3808\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 1.7500 Validation Accuracy: 0.3912\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 1.6574 Validation Accuracy: 0.4006\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 1.7084 Validation Accuracy: 0.3814\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 1.7201 Validation Accuracy: 0.3820\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.8020 Validation Accuracy: 0.3852\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 1.7693 Validation Accuracy: 0.3794\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 1.6475 Validation Accuracy: 0.3988\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 1.6887 Validation Accuracy: 0.3802\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 1.6848 Validation Accuracy: 0.4018\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.7734 Validation Accuracy: 0.4020\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 1.7375 Validation Accuracy: 0.3924\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 1.6037 Validation Accuracy: 0.4108\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 1.6395 Validation Accuracy: 0.3974\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 1.6668 Validation Accuracy: 0.4046\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.7436 Validation Accuracy: 0.4222\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 1.6980 Validation Accuracy: 0.4032\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 1.5762 Validation Accuracy: 0.4176\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 1.5990 Validation Accuracy: 0.4154\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 1.6474 Validation Accuracy: 0.4110\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.7280 Validation Accuracy: 0.4114\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 1.6855 Validation Accuracy: 0.4066\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 1.5357 Validation Accuracy: 0.4182\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 1.5753 Validation Accuracy: 0.4286\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 1.6215 Validation Accuracy: 0.4254\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.6923 Validation Accuracy: 0.4224\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 1.6589 Validation Accuracy: 0.4238\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 1.5164 Validation Accuracy: 0.4458\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 1.5567 Validation Accuracy: 0.4424\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 1.5956 Validation Accuracy: 0.4474\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.6747 Validation Accuracy: 0.4356\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 1.6259 Validation Accuracy: 0.4434\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 1.4652 Validation Accuracy: 0.4562\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 1.5352 Validation Accuracy: 0.4278\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 1.5784 Validation Accuracy: 0.4482\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.6342 Validation Accuracy: 0.4498\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 1.6064 Validation Accuracy: 0.4534\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 1.4789 Validation Accuracy: 0.4362\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 1.4914 Validation Accuracy: 0.4502\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 1.5570 Validation Accuracy: 0.4610\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.6320 Validation Accuracy: 0.4516\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 1.5782 Validation Accuracy: 0.4546\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 1.4202 Validation Accuracy: 0.4734\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 1.5013 Validation Accuracy: 0.4436\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 1.5335 Validation Accuracy: 0.4572\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.5985 Validation Accuracy: 0.4698\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 1.5642 Validation Accuracy: 0.4630\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 1.3995 Validation Accuracy: 0.4670\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 1.4299 Validation Accuracy: 0.4686\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 1.4925 Validation Accuracy: 0.4788\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.6005 Validation Accuracy: 0.4658\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 1.5828 Validation Accuracy: 0.4398\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 1.3716 Validation Accuracy: 0.4758\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 1.4547 Validation Accuracy: 0.4560\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 1.4788 Validation Accuracy: 0.4790\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.5806 Validation Accuracy: 0.4656\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 1.5423 Validation Accuracy: 0.4686\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 1.3567 Validation Accuracy: 0.4794\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 1.4119 Validation Accuracy: 0.4666\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 1.4612 Validation Accuracy: 0.4836\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.5548 Validation Accuracy: 0.4812\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 1.4899 Validation Accuracy: 0.4842\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 1.3306 Validation Accuracy: 0.4908\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 1.3747 Validation Accuracy: 0.4814\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 1.4548 Validation Accuracy: 0.4726\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.5347 Validation Accuracy: 0.4898\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 1.4978 Validation Accuracy: 0.4686\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 1.3458 Validation Accuracy: 0.4726\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 1.3669 Validation Accuracy: 0.4688\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 1.4351 Validation Accuracy: 0.4858\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.5181 Validation Accuracy: 0.4898\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 1.4697 Validation Accuracy: 0.4814\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 1.2926 Validation Accuracy: 0.4958\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 1.3367 Validation Accuracy: 0.4914\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 1.4184 Validation Accuracy: 0.4964\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.5118 Validation Accuracy: 0.4890\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 1.4406 Validation Accuracy: 0.4974\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 1.3105 Validation Accuracy: 0.4934\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 1.3511 Validation Accuracy: 0.4860\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 1.4083 Validation Accuracy: 0.5020\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.4838 Validation Accuracy: 0.4998\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 1.4205 Validation Accuracy: 0.4882\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 1.2794 Validation Accuracy: 0.5040\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 1.3297 Validation Accuracy: 0.4898\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 1.3856 Validation Accuracy: 0.4990\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.5039 Validation Accuracy: 0.4914\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 1.4234 Validation Accuracy: 0.4996\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 1.3018 Validation Accuracy: 0.5064\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 1.3105 Validation Accuracy: 0.5012\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 1.3767 Validation Accuracy: 0.5080\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.4768 Validation Accuracy: 0.4982\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 1.4100 Validation Accuracy: 0.5018\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 1.2660 Validation Accuracy: 0.5076\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 1.2958 Validation Accuracy: 0.4996\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 1.3687 Validation Accuracy: 0.5038\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.4622 Validation Accuracy: 0.5048\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 1.4023 Validation Accuracy: 0.4960\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 1.2523 Validation Accuracy: 0.5114\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 1.2852 Validation Accuracy: 0.5058\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 1.3712 Validation Accuracy: 0.5052\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.4631 Validation Accuracy: 0.5160\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 1.3881 Validation Accuracy: 0.5046\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 1.2408 Validation Accuracy: 0.5244\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 1.2701 Validation Accuracy: 0.5214\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 1.3472 Validation Accuracy: 0.5264\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.4502 Validation Accuracy: 0.5220\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 1.3583 Validation Accuracy: 0.5218\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 1.2619 Validation Accuracy: 0.5192\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 1.2723 Validation Accuracy: 0.5052\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 1.3242 Validation Accuracy: 0.5242\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.4141 Validation Accuracy: 0.5128\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 1.3568 Validation Accuracy: 0.5144\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 1.2067 Validation Accuracy: 0.5284\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 1.2480 Validation Accuracy: 0.5216\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 1.3053 Validation Accuracy: 0.5262\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.4187 Validation Accuracy: 0.5146\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 1.3559 Validation Accuracy: 0.5186\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 1.1934 Validation Accuracy: 0.5334\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 1.2459 Validation Accuracy: 0.5158\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 1.3007 Validation Accuracy: 0.5216\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.3957 Validation Accuracy: 0.5326\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 1.3212 Validation Accuracy: 0.5308\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 1.1885 Validation Accuracy: 0.5418\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 1.2258 Validation Accuracy: 0.5342\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 1.3051 Validation Accuracy: 0.5374\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.3938 Validation Accuracy: 0.5218\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 1.3125 Validation Accuracy: 0.5238\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 1.1631 Validation Accuracy: 0.5438\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 1.2286 Validation Accuracy: 0.5296\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 1.2774 Validation Accuracy: 0.5392\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.4044 Validation Accuracy: 0.5316\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 1.3200 Validation Accuracy: 0.5320\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 1.1876 Validation Accuracy: 0.5432\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 1.2239 Validation Accuracy: 0.5086\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 1.2756 Validation Accuracy: 0.5308\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.3623 Validation Accuracy: 0.5340\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 1.3058 Validation Accuracy: 0.5286\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 1.1549 Validation Accuracy: 0.5392\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 1.2106 Validation Accuracy: 0.5258\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 1.2914 Validation Accuracy: 0.5390\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.3550 Validation Accuracy: 0.5406\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 1.2924 Validation Accuracy: 0.5434\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 1.1767 Validation Accuracy: 0.5446\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 1.1974 Validation Accuracy: 0.5468\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 1.2812 Validation Accuracy: 0.5356\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.3719 Validation Accuracy: 0.5400\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 1.3007 Validation Accuracy: 0.5324\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 1.1692 Validation Accuracy: 0.5420\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 1.1803 Validation Accuracy: 0.5406\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 1.2571 Validation Accuracy: 0.5404\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.3330 Validation Accuracy: 0.5450\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 1.2984 Validation Accuracy: 0.5404\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 1.1345 Validation Accuracy: 0.5528\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 1.1720 Validation Accuracy: 0.5428\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 1.2405 Validation Accuracy: 0.5384\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.3530 Validation Accuracy: 0.5368\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 1.2696 Validation Accuracy: 0.5444\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 1.1388 Validation Accuracy: 0.5518\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 1.1736 Validation Accuracy: 0.5364\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 1.2395 Validation Accuracy: 0.5502\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.3486 Validation Accuracy: 0.5348\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 1.2526 Validation Accuracy: 0.5468\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 1.1243 Validation Accuracy: 0.5500\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 1.1684 Validation Accuracy: 0.5460\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 1.2272 Validation Accuracy: 0.5530\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 1.3463 Validation Accuracy: 0.5406\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 1.2292 Validation Accuracy: 0.5588\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 1.1093 Validation Accuracy: 0.5602\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 1.1488 Validation Accuracy: 0.5566\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 1.2200 Validation Accuracy: 0.5508\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 1.3059 Validation Accuracy: 0.5560\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 1.2316 Validation Accuracy: 0.5554\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 1.1362 Validation Accuracy: 0.5502\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 1.1459 Validation Accuracy: 0.5506\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 1.2110 Validation Accuracy: 0.5488\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 1.3256 Validation Accuracy: 0.5374\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 1.2349 Validation Accuracy: 0.5570\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 1.1150 Validation Accuracy: 0.5592\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 1.1483 Validation Accuracy: 0.5600\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 1.1849 Validation Accuracy: 0.5654\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 1.3024 Validation Accuracy: 0.5500\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 1.2245 Validation Accuracy: 0.5484\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 1.1526 Validation Accuracy: 0.5470\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 1.1408 Validation Accuracy: 0.5576\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 1.2222 Validation Accuracy: 0.5626\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 1.2824 Validation Accuracy: 0.5560\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 1.2211 Validation Accuracy: 0.5556\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 1.1103 Validation Accuracy: 0.5592\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 1.1202 Validation Accuracy: 0.5612\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 1.1717 Validation Accuracy: 0.5672\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 1.2787 Validation Accuracy: 0.5550\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 1.2167 Validation Accuracy: 0.5594\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 1.0666 Validation Accuracy: 0.5696\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 1.1267 Validation Accuracy: 0.5732\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 1.1817 Validation Accuracy: 0.5724\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 1.2840 Validation Accuracy: 0.5530\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 1.2156 Validation Accuracy: 0.5562\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 1.0880 Validation Accuracy: 0.5716\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 1.1105 Validation Accuracy: 0.5686\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 1.1587 Validation Accuracy: 0.5734\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 1.2580 Validation Accuracy: 0.5626\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 1.1882 Validation Accuracy: 0.5718\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 1.0750 Validation Accuracy: 0.5690\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 1.1112 Validation Accuracy: 0.5654\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 1.1644 Validation Accuracy: 0.5714\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 1.2341 Validation Accuracy: 0.5606\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 1.1908 Validation Accuracy: 0.5748\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 1.1028 Validation Accuracy: 0.5682\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 1.0967 Validation Accuracy: 0.5660\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 1.1647 Validation Accuracy: 0.5692\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 1.2545 Validation Accuracy: 0.5752\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss: 1.2180 Validation Accuracy: 0.5622\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss: 1.0867 Validation Accuracy: 0.5552\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss: 1.1067 Validation Accuracy: 0.5752\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss: 1.1825 Validation Accuracy: 0.5724\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 1.2302 Validation Accuracy: 0.5798\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss: 1.1693 Validation Accuracy: 0.5720\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss: 1.0660 Validation Accuracy: 0.5624\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss: 1.0880 Validation Accuracy: 0.5778\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss: 1.1397 Validation Accuracy: 0.5700\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 1.2613 Validation Accuracy: 0.5742\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss: 1.2001 Validation Accuracy: 0.5640\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss: 1.0538 Validation Accuracy: 0.5806\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss: 1.0810 Validation Accuracy: 0.5768\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss: 1.1324 Validation Accuracy: 0.5832\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 1.2231 Validation Accuracy: 0.5858\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss: 1.1733 Validation Accuracy: 0.5702\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss: 1.0390 Validation Accuracy: 0.5788\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss: 1.0582 Validation Accuracy: 0.5782\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss: 1.1097 Validation Accuracy: 0.5852\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 1.1999 Validation Accuracy: 0.5842\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss: 1.1835 Validation Accuracy: 0.5762\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss: 1.0543 Validation Accuracy: 0.5802\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss: 1.0768 Validation Accuracy: 0.5846\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss: 1.1202 Validation Accuracy: 0.5886\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 1.2376 Validation Accuracy: 0.5736\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss: 1.1432 Validation Accuracy: 0.5864\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss: 1.0481 Validation Accuracy: 0.5836\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss: 1.0584 Validation Accuracy: 0.5780\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss: 1.1218 Validation Accuracy: 0.5766\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 1.2145 Validation Accuracy: 0.5748\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss: 1.1383 Validation Accuracy: 0.5794\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss: 1.0446 Validation Accuracy: 0.5890\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss: 1.0391 Validation Accuracy: 0.5818\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss: 1.0833 Validation Accuracy: 0.5862\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 1.2028 Validation Accuracy: 0.5870\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss: 1.1399 Validation Accuracy: 0.5834\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss: 1.0320 Validation Accuracy: 0.5870\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss: 1.0615 Validation Accuracy: 0.5864\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss: 1.0972 Validation Accuracy: 0.5838\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 1.1915 Validation Accuracy: 0.5888\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss: 1.1486 Validation Accuracy: 0.5850\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss: 1.0285 Validation Accuracy: 0.5866\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss: 1.0404 Validation Accuracy: 0.5846\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss: 1.0994 Validation Accuracy: 0.5892\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 1.2191 Validation Accuracy: 0.5826\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss: 1.1444 Validation Accuracy: 0.5918\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss: 1.0290 Validation Accuracy: 0.5838\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss: 1.0319 Validation Accuracy: 0.5948\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss: 1.1083 Validation Accuracy: 0.5900\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 1.2064 Validation Accuracy: 0.5856\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss: 1.1155 Validation Accuracy: 0.5912\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss: 1.0208 Validation Accuracy: 0.5906\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss: 1.0386 Validation Accuracy: 0.5950\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss: 1.0839 Validation Accuracy: 0.5962\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 1.1719 Validation Accuracy: 0.5866\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss: 1.1247 Validation Accuracy: 0.5910\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss: 1.0336 Validation Accuracy: 0.5934\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss: 1.0467 Validation Accuracy: 0.5930\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss: 1.0822 Validation Accuracy: 0.5836\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 1.1683 Validation Accuracy: 0.5880\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss: 1.1284 Validation Accuracy: 0.5788\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss: 1.0160 Validation Accuracy: 0.5900\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss: 1.0163 Validation Accuracy: 0.5844\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss: 1.0871 Validation Accuracy: 0.5884\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 1.1699 Validation Accuracy: 0.5930\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss: 1.1088 Validation Accuracy: 0.5838\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss: 1.0214 Validation Accuracy: 0.5894\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss: 1.0383 Validation Accuracy: 0.5950\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss: 1.0993 Validation Accuracy: 0.5932\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 1.1657 Validation Accuracy: 0.5932\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss: 1.0993 Validation Accuracy: 0.5820\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss: 1.0173 Validation Accuracy: 0.5908\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss: 1.0116 Validation Accuracy: 0.5952\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss: 1.0772 Validation Accuracy: 0.5988\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 1.1425 Validation Accuracy: 0.5978\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss: 1.1148 Validation Accuracy: 0.5790\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss: 0.9834 Validation Accuracy: 0.5950\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss: 1.0212 Validation Accuracy: 0.5988\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss: 1.0657 Validation Accuracy: 0.6014\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 1.1534 Validation Accuracy: 0.6002\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss: 1.0948 Validation Accuracy: 0.5942\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss: 1.0058 Validation Accuracy: 0.5946\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss: 0.9994 Validation Accuracy: 0.6000\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss: 1.0508 Validation Accuracy: 0.6018\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 1.1688 Validation Accuracy: 0.5850\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss: 1.1195 Validation Accuracy: 0.5922\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss: 1.0004 Validation Accuracy: 0.5920\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss: 0.9889 Validation Accuracy: 0.6014\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss: 1.0496 Validation Accuracy: 0.6050\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 1.1433 Validation Accuracy: 0.5952\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss: 1.0707 Validation Accuracy: 0.6058\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss: 0.9892 Validation Accuracy: 0.6020\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss: 1.0026 Validation Accuracy: 0.6014\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss: 1.0443 Validation Accuracy: 0.6022\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 1.1352 Validation Accuracy: 0.5952\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss: 1.0932 Validation Accuracy: 0.6042\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss: 0.9838 Validation Accuracy: 0.5972\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss: 0.9799 Validation Accuracy: 0.5972\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss: 1.0469 Validation Accuracy: 0.6056\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 1.1466 Validation Accuracy: 0.5952\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss: 1.0663 Validation Accuracy: 0.6070\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss: 0.9776 Validation Accuracy: 0.6020\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss: 0.9863 Validation Accuracy: 0.5988\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss: 1.0576 Validation Accuracy: 0.5888\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 1.1209 Validation Accuracy: 0.6046\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss: 1.0603 Validation Accuracy: 0.6010\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss: 0.9751 Validation Accuracy: 0.6022\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss: 0.9819 Validation Accuracy: 0.6036\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss: 1.0352 Validation Accuracy: 0.6080\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 1.1205 Validation Accuracy: 0.6054\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss: 1.0535 Validation Accuracy: 0.6022\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss: 0.9558 Validation Accuracy: 0.6086\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss: 0.9802 Validation Accuracy: 0.6084\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss: 1.0137 Validation Accuracy: 0.6096\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 1.1089 Validation Accuracy: 0.6050\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss: 1.0563 Validation Accuracy: 0.6030\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss: 0.9660 Validation Accuracy: 0.5972\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss: 0.9806 Validation Accuracy: 0.6042\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss: 1.0233 Validation Accuracy: 0.5918\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 1.1013 Validation Accuracy: 0.6032\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss: 1.0533 Validation Accuracy: 0.6076\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss: 0.9977 Validation Accuracy: 0.5940\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss: 0.9709 Validation Accuracy: 0.6086\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss: 1.0177 Validation Accuracy: 0.6058\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 1.1133 Validation Accuracy: 0.6074\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss: 1.0641 Validation Accuracy: 0.6040\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss: 0.9757 Validation Accuracy: 0.6010\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss: 0.9625 Validation Accuracy: 0.6114\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss: 1.0085 Validation Accuracy: 0.6056\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 1.1031 Validation Accuracy: 0.6108\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss: 1.0263 Validation Accuracy: 0.6102\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss: 0.9662 Validation Accuracy: 0.6020\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss: 0.9678 Validation Accuracy: 0.6114\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss: 1.0085 Validation Accuracy: 0.6086\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 1.0994 Validation Accuracy: 0.6164\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss: 1.0700 Validation Accuracy: 0.6062\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss: 0.9574 Validation Accuracy: 0.6094\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss: 0.9504 Validation Accuracy: 0.6018\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss: 1.0162 Validation Accuracy: 0.6078\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 1.0963 Validation Accuracy: 0.6114\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss: 1.0393 Validation Accuracy: 0.6122\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss: 0.9727 Validation Accuracy: 0.6076\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss: 0.9616 Validation Accuracy: 0.6102\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss: 1.0104 Validation Accuracy: 0.6170\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 1.0864 Validation Accuracy: 0.6158\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss: 1.0402 Validation Accuracy: 0.6114\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss: 0.9437 Validation Accuracy: 0.6144\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss: 0.9446 Validation Accuracy: 0.6104\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss: 1.0043 Validation Accuracy: 0.6078\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 1.1014 Validation Accuracy: 0.6080\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss: 1.0511 Validation Accuracy: 0.6094\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss: 0.9431 Validation Accuracy: 0.6148\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss: 0.9366 Validation Accuracy: 0.6158\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss: 1.0018 Validation Accuracy: 0.6108\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 1.0889 Validation Accuracy: 0.6114\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss: 1.0149 Validation Accuracy: 0.6066\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss: 0.9376 Validation Accuracy: 0.6118\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss: 0.9486 Validation Accuracy: 0.6098\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss: 0.9899 Validation Accuracy: 0.6116\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 1.0786 Validation Accuracy: 0.6154\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss: 1.0605 Validation Accuracy: 0.6016\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss: 0.9472 Validation Accuracy: 0.6142\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss: 0.9440 Validation Accuracy: 0.6078\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss: 0.9806 Validation Accuracy: 0.6166\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 1.0801 Validation Accuracy: 0.6138\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss: 1.0425 Validation Accuracy: 0.6126\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss: 0.9566 Validation Accuracy: 0.6122\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss: 0.9541 Validation Accuracy: 0.6154\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss: 1.0002 Validation Accuracy: 0.6062\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 1.0743 Validation Accuracy: 0.6162\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss: 1.0181 Validation Accuracy: 0.6012\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss: 0.9326 Validation Accuracy: 0.6156\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss: 0.9430 Validation Accuracy: 0.6186\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss: 1.0052 Validation Accuracy: 0.6048\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 1.0759 Validation Accuracy: 0.6128\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss: 1.0118 Validation Accuracy: 0.6208\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss: 0.9346 Validation Accuracy: 0.6192\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss: 0.9244 Validation Accuracy: 0.6192\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss: 0.9775 Validation Accuracy: 0.6168\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 1.0722 Validation Accuracy: 0.6132\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss: 1.0213 Validation Accuracy: 0.6140\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss: 0.9313 Validation Accuracy: 0.6156\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss: 0.9200 Validation Accuracy: 0.6128\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss: 0.9851 Validation Accuracy: 0.6190\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 1.0752 Validation Accuracy: 0.6140\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss: 1.0171 Validation Accuracy: 0.6128\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss: 0.9259 Validation Accuracy: 0.6158\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss: 0.9389 Validation Accuracy: 0.6158\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss: 0.9796 Validation Accuracy: 0.6154\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 1.0747 Validation Accuracy: 0.6186\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss: 1.0301 Validation Accuracy: 0.6080\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss: 0.9211 Validation Accuracy: 0.6094\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss: 0.9201 Validation Accuracy: 0.6212\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss: 0.9974 Validation Accuracy: 0.6134\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 1.0586 Validation Accuracy: 0.6190\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss: 1.0215 Validation Accuracy: 0.6166\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss: 0.9372 Validation Accuracy: 0.6146\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss: 0.9040 Validation Accuracy: 0.6190\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss: 0.9601 Validation Accuracy: 0.6210\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 1.0340 Validation Accuracy: 0.6230\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss: 0.9992 Validation Accuracy: 0.6198\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss: 0.9263 Validation Accuracy: 0.6094\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss: 0.9089 Validation Accuracy: 0.6184\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss: 0.9518 Validation Accuracy: 0.6154\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 1.1005 Validation Accuracy: 0.5968\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss: 0.9990 Validation Accuracy: 0.6116\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss: 0.9075 Validation Accuracy: 0.6202\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss: 0.9260 Validation Accuracy: 0.6228\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss: 0.9623 Validation Accuracy: 0.6176\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 1.0622 Validation Accuracy: 0.6206\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss: 0.9966 Validation Accuracy: 0.6182\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss: 0.9064 Validation Accuracy: 0.6166\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss: 0.9057 Validation Accuracy: 0.6234\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss: 0.9666 Validation Accuracy: 0.6206\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 1.0581 Validation Accuracy: 0.6174\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss: 0.9911 Validation Accuracy: 0.6152\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss: 0.9086 Validation Accuracy: 0.6216\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss: 0.9170 Validation Accuracy: 0.6152\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss: 0.9479 Validation Accuracy: 0.6232\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 1.0542 Validation Accuracy: 0.6162\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss: 1.0006 Validation Accuracy: 0.6202\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss: 0.9040 Validation Accuracy: 0.6212\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss: 0.8981 Validation Accuracy: 0.6226\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss: 0.9596 Validation Accuracy: 0.6220\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 1.0565 Validation Accuracy: 0.6210\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss: 0.9790 Validation Accuracy: 0.6248\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss: 0.9053 Validation Accuracy: 0.6184\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss: 0.8960 Validation Accuracy: 0.6232\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss: 0.9414 Validation Accuracy: 0.6224\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 1.0306 Validation Accuracy: 0.6204\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss: 0.9977 Validation Accuracy: 0.6178\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss: 0.9057 Validation Accuracy: 0.6222\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss: 0.8823 Validation Accuracy: 0.6268\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss: 0.9335 Validation Accuracy: 0.6232\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 1.0192 Validation Accuracy: 0.6296\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss: 0.9662 Validation Accuracy: 0.6242\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss: 0.8858 Validation Accuracy: 0.6268\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss: 0.9155 Validation Accuracy: 0.6148\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss: 0.9521 Validation Accuracy: 0.6174\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 1.0289 Validation Accuracy: 0.6254\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss: 0.9878 Validation Accuracy: 0.6248\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss: 0.9102 Validation Accuracy: 0.6264\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss: 0.8913 Validation Accuracy: 0.6224\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss: 0.9549 Validation Accuracy: 0.6124\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 1.0296 Validation Accuracy: 0.6214\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss: 0.9824 Validation Accuracy: 0.6204\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss: 0.9084 Validation Accuracy: 0.6232\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss: 0.8899 Validation Accuracy: 0.6216\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss: 0.9389 Validation Accuracy: 0.6216\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5714614003896713\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2645a3a2470>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
